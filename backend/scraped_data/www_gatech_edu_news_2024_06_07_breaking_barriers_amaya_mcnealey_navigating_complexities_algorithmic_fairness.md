[Enable accessibility](https://www.gatech.edu/news/2024/06/07/breaking-barriers-amaya-mcnealey-navigating-complexities-algorithmic-fairness#)

 [Skip to main navigation](https://www.gatech.edu/news/2024/06/07/breaking-barriers-amaya-mcnealey-navigating-complexities-algorithmic-fairness#main-navigation) [Skip to main content](https://www.gatech.edu/news/2024/06/07/breaking-barriers-amaya-mcnealey-navigating-complexities-algorithmic-fairness#main-content)

# Breaking Barriers with Amaya McNealey: Navigating the Complexities of Algorithmic Fairness

# Breaking Barriers with Amaya McNealey: Navigating the Complexities of Algorithmic Fairness

Jun 07, 2024


In her presentation at the [2024 Emerging Researchers National (ERN) Conference in STEM](https://emerging-researchers.org/) held in Washington, D.C., ISyE PhD student [Amaya McNealey](https://www.isye.gatech.edu/users/amaya-mcnealey) seized 1st place in the Graduate Oral Presentation in the Data Science, Physiology, and Health category.

Currently in her second year as a PhD student in the [H. Milton Stewart School of Industrial and Systems Engineering (ISyE)](http://www.isye.gatech.edu/) program, Amaya McNealey has directed her research and focus in healthcare and social systems. Co-advised by ISyE professors, [Lauren Steimle](https://www.isye.gatech.edu/users/lauren-steimle), and [Gian-Gabriel Garcia](https://www.isye.gatech.edu/users/gian-gabriel-garcia), McNealey has worked with them to develop models that aim to understand and mitigate biases in healthcare algorithms.

At the ERN Conference in STEM, McNealey’s research analyzed the potential for algorithmic bias in clinical decision support, particularly within the realm of maternal health disparities.

Through her work, McNealey sheds light on the critical need for comprehensive solutions to mitigate biases perpetuated by machine learning (ML) algorithms.

Nationwide and particularly in Georgia, there’s been a sharp increase in maternal adverse outcomes for Black and Hispanic women, in which her research investigates the racial disparities. Her work focused on the impact of removing race as a predictor in an ML model used to help pregnant people decide whether to deliver via C-section or vaginally.

“Removing race isn’t simply always going to be the solution to reducing disparities in these models – additional research to understand what is race actually trying to capture in these models and incorporate these underlying factors in a way that maintains model accuracy while accounting for fairness.”

By unveiling how simply removing race from ML algorithms can still lead to disproportionate impact on historically marginalized populations, her work advocates for interdisciplinary collaboration and practical implementation to ensure equitable outcomes for all.

With that type of data materializing, McNealey plans to create a pipeline for fair machine learning development with metrics that can be used in an effective way.

“Model fairness is essentially looking at how either prediction or outcomes of a machine learning model affects the population. When we create our ML models, typically the first thing we look at is accuracy, but we do not regularly investigate the downstream effects or decisions that are made as a result of the model.”

In collaboration with Emory University, McNealey has gained insight into how these models are used in practice which has allowed her to consider how this impacts her work and additionally the community at hand.

Leaning on recent advances in algorithmic fairness, Amaya challenges conventional approaches by highlighting the limitations of merely removing race indicators from ML models.

By advocating for holistic solutions, she is already paving the way for meaningful progress towards impartial practices in ML research.

“With this type of work, we don’t see it just in healthcare, we see it in loan applications, criminal recidivism… I think this can be very impactful for a lot of different communities and applications.”

Looking ahead, McNealey envisions a future where accessible tools and metrics empower stakeholders to detect, justify, and mitigate biases effectively.

Her award-winning presentation exemplifies inclusive excellence and leads the next generation to the new era of shaping diverse perspectives on comprehensive equity in ML research. As we celebrate her achievements, let us embrace the opportunity to pursue technologies that uplift and empower every individual irrespective of race, gender or background.

\\_\\_\\_

By: Camille Carpenter, Communications Manager

This website uses cookies. For more information, review our [Privacy & Legal Notice](https://www.gatech.edu/privacy). Questions? Please email [privacy@gatech.edu](mailto:privacy@gatech.edu).

More info

AcceptNo, thanks